{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder (MLP) Tensorflow\n",
    "Train a variational autoencoder with MNIST dataset\n",
    "\n",
    "#### References:\n",
    "* http://kvfrans.com/variational-autoencoders-explained/\n",
    "* https://github.com/kvfrans/variational-autoencoder\n",
    "* https://github.com/int8/VAE_tensorflow\n",
    "* http://int8.io/variational-autoencoder-in-tensorflow/\n",
    "* http://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in.html\n",
    "* http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html\n",
    "* https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "* https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\n",
    "* https://arxiv.org/pdf/1606.05908.pdf\n",
    "* https://arxiv.org/pdf/1312.6114.pdf\n",
    "* http://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/\n",
    "* https://www.tensorflow.org/get_started/embedding_viz\n",
    "* https://www.youtube.com/watch?v=eBbEDRsCmv4\n",
    "* https://github.com/normanheckscher/mnist-tensorboard-embeddings\n",
    "* http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)\n",
    "\n",
    "# Delete directory if exist\n",
    "if os.path.exists('/tmp/vae_cnn'):    \n",
    "    os.system(\"rm -rf /tmp/vae_cnn\")\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import VAE_CNN\n",
    "model = VAE_CNN(latent_size = 20)\n",
    "model_in = model.input\n",
    "model_out = model.output\n",
    "model_out_flat = model.output_flat\n",
    "z_mean = model.z_mean\n",
    "z_stddev = model.z_stddev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"VAE_LOSS\"):\n",
    "    # Binary cross entropy\n",
    "    #generation_loss = -tf.reduce_sum(model_in * tf.log(1e-8 + model_out_flat) + (1-model_in) * tf.log(1e-8 + 1 - model_out_flat),1)\n",
    "    \n",
    "    # L2 Loss\n",
    "    generation_loss = tf.nn.l2_loss(model_in-model_out_flat)\n",
    "    \n",
    "    # KL Loss\n",
    "    latent_loss = 0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(z_stddev) - tf.log(tf.square(z_stddev)) - 1,1)\n",
    "    \n",
    "    # Merge the losses\n",
    "    loss = tf.reduce_mean(generation_loss + latent_loss)\n",
    "\n",
    "# Solver configuration\n",
    "with tf.name_scope(\"Solver\"):\n",
    "    train_step = tf.train.AdamOptimizer(0.00001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Avoid allocating the whole memory\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "#sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some tensors to observe on Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.summary.image(\"input_image\", model.image_in, 4)\n",
    "tf.summary.image(\"output_image\", model_out, 4)\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "merged_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"/tmp/vae_cnn/1\")\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "# Create saver object\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100 loss:3816\n",
      "Epoch: 1/100 loss:2096\n",
      "Epoch: 2/100 loss:1827\n",
      "Epoch: 3/100 loss:1655\n",
      "Epoch: 4/100 loss:1572\n",
      "Epoch: 5/100 loss:1508\n",
      "Epoch: 6/100 loss:1397\n",
      "Epoch: 7/100 loss:1415\n",
      "Epoch: 8/100 loss:1296\n",
      "Epoch: 9/100 loss:1266\n",
      "Epoch: 10/100 loss:1358\n",
      "Epoch: 11/100 loss:1262\n",
      "Epoch: 12/100 loss:1254\n",
      "Epoch: 13/100 loss:1205\n",
      "Epoch: 14/100 loss:1068\n",
      "Epoch: 15/100 loss:1018\n",
      "Epoch: 16/100 loss:954\n",
      "Epoch: 17/100 loss:880\n",
      "Epoch: 18/100 loss:823\n",
      "Epoch: 19/100 loss:812\n",
      "Epoch: 20/100 loss:734\n",
      "Epoch: 21/100 loss:750\n",
      "Epoch: 22/100 loss:645\n",
      "Epoch: 23/100 loss:665\n",
      "Epoch: 24/100 loss:648\n",
      "Epoch: 25/100 loss:650\n",
      "Epoch: 26/100 loss:648\n",
      "Epoch: 27/100 loss:600\n",
      "Epoch: 28/100 loss:592\n",
      "Epoch: 29/100 loss:586\n",
      "Epoch: 30/100 loss:517\n",
      "Epoch: 31/100 loss:569\n",
      "Epoch: 32/100 loss:565\n",
      "Epoch: 33/100 loss:499\n",
      "Epoch: 34/100 loss:534\n",
      "Epoch: 35/100 loss:518\n",
      "Epoch: 36/100 loss:520\n",
      "Epoch: 37/100 loss:461\n",
      "Epoch: 38/100 loss:491\n",
      "Epoch: 39/100 loss:475\n",
      "Epoch: 40/100 loss:521\n",
      "Epoch: 41/100 loss:451\n",
      "Epoch: 42/100 loss:456\n",
      "Epoch: 43/100 loss:502\n",
      "Epoch: 44/100 loss:446\n",
      "Epoch: 45/100 loss:431\n",
      "Epoch: 46/100 loss:432\n",
      "Epoch: 47/100 loss:430\n",
      "Epoch: 48/100 loss:407\n",
      "Epoch: 49/100 loss:472\n",
      "Epoch: 50/100 loss:430\n",
      "Epoch: 51/100 loss:423\n",
      "Epoch: 52/100 loss:404\n",
      "Epoch: 53/100 loss:400\n",
      "Epoch: 54/100 loss:362\n",
      "Epoch: 55/100 loss:391\n",
      "Epoch: 56/100 loss:423\n",
      "Epoch: 57/100 loss:402\n",
      "Epoch: 58/100 loss:342\n",
      "Epoch: 59/100 loss:404\n",
      "Epoch: 60/100 loss:379\n",
      "Epoch: 61/100 loss:376\n",
      "Epoch: 62/100 loss:330\n",
      "Epoch: 63/100 loss:407\n",
      "Epoch: 64/100 loss:356\n",
      "Epoch: 65/100 loss:336\n",
      "Epoch: 66/100 loss:354\n",
      "Epoch: 67/100 loss:404\n",
      "Epoch: 68/100 loss:393\n",
      "Epoch: 69/100 loss:336\n",
      "Epoch: 70/100 loss:371\n",
      "Epoch: 71/100 loss:349\n",
      "Epoch: 72/100 loss:389\n",
      "Epoch: 73/100 loss:348\n",
      "Epoch: 74/100 loss:367\n",
      "Epoch: 75/100 loss:380\n",
      "Epoch: 76/100 loss:360\n",
      "Epoch: 77/100 loss:351\n",
      "Epoch: 78/100 loss:358\n",
      "Epoch: 79/100 loss:331\n",
      "Epoch: 80/100 loss:327\n",
      "Epoch: 81/100 loss:352\n",
      "Epoch: 82/100 loss:353\n",
      "Epoch: 83/100 loss:328\n",
      "Epoch: 84/100 loss:342\n",
      "Epoch: 85/100 loss:359\n",
      "Epoch: 86/100 loss:329\n",
      "Epoch: 87/100 loss:310\n",
      "Epoch: 88/100 loss:331\n",
      "Epoch: 89/100 loss:346\n",
      "Epoch: 90/100 loss:366\n",
      "Epoch: 91/100 loss:361\n",
      "Epoch: 92/100 loss:334\n",
      "Epoch: 93/100 loss:329\n",
      "Epoch: 94/100 loss:329\n",
      "Epoch: 95/100 loss:355\n",
      "Epoch: 96/100 loss:325\n",
      "Epoch: 97/100 loss:311\n",
      "Epoch: 98/100 loss:377\n",
      "Epoch: 99/100 loss:316\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "batch_size = 100\n",
    "for epoch in range(num_epoch):\n",
    "    for i in range(int(mnist.train.num_examples / batch_size)):\n",
    "        # Get batch of 50 images\n",
    "        batch = mnist.train.next_batch(50)\n",
    "\n",
    "        # Dump summary\n",
    "        if i % 5000 == 0:            \n",
    "            # Other summaries\n",
    "            s = sess.run(merged_summary, feed_dict={model_in:batch[0]})\n",
    "            writer.add_summary(s,i) \n",
    "            \n",
    "            # Save embedding (for PCA, TSNE)\n",
    "            sess.run(model.assignment, feed_dict={model_in: batch[0]})\n",
    "            saver.save(sess, os.path.join(\"/tmp/vae_cnn/\", \"model.ckpt\"), i)\n",
    "\n",
    "\n",
    "        # Train actually here (Also get loss value)    \n",
    "        _, val_loss = sess.run((train_step, loss), feed_dict={model_in:batch[0]})\n",
    "\n",
    "        #if i % 5000:\n",
    "            #print('Generation loss: %d, latent loss: %d' % (np.mean(gen_loss), np.mean(lat_loss)))\n",
    "    print('Epoch: %d/%d loss:%d' % (epoch, num_epoch, val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
