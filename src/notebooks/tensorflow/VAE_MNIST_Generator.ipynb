{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder Generator Tensorflow\n",
    "This should open a pre-trained VAE and become a Data generator\n",
    "\n",
    "#### References:\n",
    "* http://kvfrans.com/variational-autoencoders-explained/\n",
    "* https://github.com/kvfrans/variational-autoencoder\n",
    "* https://github.com/int8/VAE_tensorflow\n",
    "* http://int8.io/variational-autoencoder-in-tensorflow/\n",
    "* http://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in.html\n",
    "* http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html\n",
    "* https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "* https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\n",
    "* https://arxiv.org/pdf/1606.05908.pdf\n",
    "* https://arxiv.org/pdf/1312.6114.pdf\n",
    "* http://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/\n",
    "* https://www.tensorflow.org/get_started/embedding_viz\n",
    "* https://www.youtube.com/watch?v=eBbEDRsCmv4\n",
    "* https://www.youtube.com/watch?v=bbOFvxbMIV0\n",
    "* https://www.youtube.com/watch?v=P78QYjWh5sM\n",
    "* https://github.com/normanheckscher/mnist-tensorboard-embeddings\n",
    "* http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)\n",
    "\n",
    "SAVE_FOLDER='/tmp/vae_cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import VAE_CNN_GEN\n",
    "model = VAE_CNN_GEN(latent_size = 20)\n",
    "model_in = model.input\n",
    "model_out = model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select only the convs\n",
    "list_params = [v for v in tf.global_variables() if \"z_matrix\" in v.name or \"conv\" in v.name ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'DECODER/z_matrix/weights:0' shape=(20, 1568) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/z_matrix/bias:0' shape=(1568,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv1/weights:0' shape=(5, 5, 16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv1/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv2/weights:0' shape=(5, 5, 1, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv2/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define saver objects to load the VAE generator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the saver object to load only the conv variables\n",
    "saver_load_autoencoder = tf.train.Saver(var_list=list_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph and create session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/vae_cnn/model-199\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Avoid allocating the whole memory\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "#sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Initialize all random variables (Weights/Bias)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Restore only the weights (From AutoEncoder)\n",
    "saver_load_autoencoder.restore(sess, \"/tmp/vae_cnn/model-199\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some input from the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e4e5142e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a latent as a normal distribution with size 20, mean 0, variance 1\n",
    "latent = np.random.normal(0, 1, [1,20])\n",
    "\n",
    "#latent = np.ones([1,20])\n",
    "#latent[0,1:10] = -1\n",
    "\n",
    "out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "plt.imshow(out_img.reshape([28,28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpi = 50\n",
    "\n",
    "def ani_frame():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    im = ax.imshow(np.random.rand(28,28),cmap='gray',interpolation='nearest')\n",
    "    #latent = np.random.normal(0, 1, [1,20])\n",
    "    #out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "    #im = ax.imshow(out_img.reshape([28,28]),cmap='gray',interpolation='nearest')\n",
    "    \n",
    "    im.set_clim([0,1])\n",
    "    fig.set_size_inches([5,5])\n",
    "\n",
    "\n",
    "    tight_layout()\n",
    "\n",
    "\n",
    "    def update_img(n):\n",
    "        #tmp = rand(300,300)\n",
    "        #im.set_data(tmp)\n",
    "        latent = np.random.normal(0, 1, [1,20])\n",
    "        out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "        im.set_data(out_img.reshape([28,28]))\n",
    "        return im\n",
    "\n",
    "    #legend(loc=0)\n",
    "    ani = animation.FuncAnimation(fig,update_img,300,interval=30)\n",
    "    writer = animation.writers['ffmpeg'](fps=30)\n",
    "\n",
    "    ani.save('demo.mp4',writer=writer,dpi=dpi)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x7f1e4c4464e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ani_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
