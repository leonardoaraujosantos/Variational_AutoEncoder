{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder Generator Tensorflow\n",
    "This should open a pre-trained VAE and become a Data generator\n",
    "\n",
    "#### References:\n",
    "* http://kvfrans.com/variational-autoencoders-explained/\n",
    "* https://github.com/kvfrans/variational-autoencoder\n",
    "* https://github.com/int8/VAE_tensorflow\n",
    "* http://int8.io/variational-autoencoder-in-tensorflow/\n",
    "* http://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in.html\n",
    "* http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html\n",
    "* https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "* https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\n",
    "* https://arxiv.org/pdf/1606.05908.pdf\n",
    "* https://arxiv.org/pdf/1312.6114.pdf\n",
    "* http://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/\n",
    "* https://www.tensorflow.org/get_started/embedding_viz\n",
    "* https://www.youtube.com/watch?v=eBbEDRsCmv4\n",
    "* https://www.youtube.com/watch?v=bbOFvxbMIV0\n",
    "* https://www.youtube.com/watch?v=P78QYjWh5sM\n",
    "* https://github.com/normanheckscher/mnist-tensorboard-embeddings\n",
    "* http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)\n",
    "\n",
    "SAVE_FOLDER='/tmp/vae_cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import VAE_CNN_GEN\n",
    "model = VAE_CNN_GEN(latent_size = 20)\n",
    "model_in = model.input\n",
    "model_out = model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select only the convs\n",
    "list_params = [v for v in tf.global_variables() if \"z_matrix\" in v.name or \"conv\" in v.name ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'DECODER/z_matrix/weights:0' shape=(20, 1568) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/z_matrix/bias:0' shape=(1568,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv1/weights:0' shape=(5, 5, 16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv1/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv2/weights:0' shape=(5, 5, 1, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv2/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define saver objects to load the VAE generator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the saver object to load only the conv variables\n",
    "saver_load_autoencoder = tf.train.Saver(var_list=list_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph and create session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/vae_cnn/model.ckpt-0\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Avoid allocating the whole memory\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "#sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Initialize all random variables (Weights/Bias)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Restore only the weights (From AutoEncoder)\n",
    "saver_load_autoencoder.restore(sess, \"/tmp/vae_cnn/model.ckpt-0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some input from the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc90e8355c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a latent as a normal distribution with size 20, mean 0, variance 1\n",
    "latent = np.random.normal(0, 1, [1,20])\n",
    "\n",
    "#latent = np.ones([1,20])\n",
    "#latent[0,1:10] = -1\n",
    "\n",
    "out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "plt.imshow(out_img.reshape([28,28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpi = 100\n",
    "\n",
    "def ani_frame():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    im = ax.imshow(np.random.rand(300,300),cmap='gray',interpolation='nearest')\n",
    "    #latent = np.random.normal(0, 1, [1,20])\n",
    "    #out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "    #im = ax.imshow(out_img.reshape([28,28]),cmap='gray',interpolation='nearest')\n",
    "    \n",
    "    im.set_clim([0,1])\n",
    "    fig.set_size_inches([5,5])\n",
    "\n",
    "\n",
    "    tight_layout()\n",
    "\n",
    "\n",
    "    def update_img(n):\n",
    "        #tmp = rand(300,300)\n",
    "        #im.set_data(tmp)\n",
    "        latent = np.random.normal(0, 1, [1,20])\n",
    "        out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "        im.set_data(out_img.reshape([28,28]))\n",
    "        return im\n",
    "\n",
    "    #legend(loc=0)\n",
    "    ani = animation.FuncAnimation(fig,update_img,300,interval=30)\n",
    "    writer = animation.writers['ffmpeg'](fps=30)\n",
    "\n",
    "    ani.save('demo.mp4',writer=writer,dpi=dpi)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x7fc8ec7954a8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ani_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
