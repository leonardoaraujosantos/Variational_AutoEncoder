{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder Generator Tensorflow\n",
    "This should open a pre-trained VAE and become a Data generator\n",
    "\n",
    "#### References:\n",
    "* http://kvfrans.com/variational-autoencoders-explained/\n",
    "* https://github.com/kvfrans/variational-autoencoder\n",
    "* https://github.com/int8/VAE_tensorflow\n",
    "* http://int8.io/variational-autoencoder-in-tensorflow/\n",
    "* http://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in.html\n",
    "* http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html\n",
    "* https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "* https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\n",
    "* https://arxiv.org/pdf/1606.05908.pdf\n",
    "* https://arxiv.org/pdf/1312.6114.pdf\n",
    "* http://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/\n",
    "* https://www.tensorflow.org/get_started/embedding_viz\n",
    "* https://www.youtube.com/watch?v=eBbEDRsCmv4\n",
    "* https://www.youtube.com/watch?v=bbOFvxbMIV0\n",
    "* https://www.youtube.com/watch?v=P78QYjWh5sM\n",
    "* https://github.com/normanheckscher/mnist-tensorboard-embeddings\n",
    "* http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)\n",
    "\n",
    "SAVE_FOLDER='/tmp/vae_cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import VAE_CNN_GEN\n",
    "model = VAE_CNN_GEN(latent_size = 20)\n",
    "model_in = model.input\n",
    "model_out = model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select only the convs\n",
    "list_params = [v for v in tf.global_variables() if \"z_matrix\" in v.name or \"conv\" in v.name ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'DECODER/z_matrix/weights:0' shape=(20, 1568) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/z_matrix/bias:0' shape=(1568,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv1/weights:0' shape=(5, 5, 16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv1/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv2/weights:0' shape=(5, 5, 1, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv2/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define saver objects to load the VAE generator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the saver object to load only the conv variables\n",
    "saver_load_autoencoder = tf.train.Saver(var_list=list_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph and create session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/vae_cnn/model.ckpt-0\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Avoid allocating the whole memory\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "#sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Initialize all random variables (Weights/Bias)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Restore only the weights (From AutoEncoder)\n",
    "saver_load_autoencoder.restore(sess, \"/tmp/vae_cnn/model.ckpt-0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some input from the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAyceHjTsHztVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8e814b0e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a latent as a normal distribution with size 20, mean 0, variance 1\n",
    "latent = np.random.normal(0, 1, [1,20])\n",
    "\n",
    "#latent = np.ones([1,20])\n",
    "#latent[0,1:10] = -1\n",
    "\n",
    "out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "plt.imshow(out_img.reshape([28,28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpi = 50\n",
    "\n",
    "def ani_frame():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    im = ax.imshow(np.random.rand(28,28),cmap='gray',interpolation='nearest')\n",
    "    #latent = np.random.normal(0, 1, [1,20])\n",
    "    #out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "    #im = ax.imshow(out_img.reshape([28,28]),cmap='gray',interpolation='nearest')\n",
    "    \n",
    "    im.set_clim([0,1])\n",
    "    fig.set_size_inches([5,5])\n",
    "\n",
    "\n",
    "    tight_layout()\n",
    "\n",
    "\n",
    "    def update_img(n):\n",
    "        #tmp = rand(300,300)\n",
    "        #im.set_data(tmp)\n",
    "        latent = np.random.normal(0, 1, [1,20])\n",
    "        out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "        im.set_data(out_img.reshape([28,28]))\n",
    "        return im\n",
    "\n",
    "    #legend(loc=0)\n",
    "    ani = animation.FuncAnimation(fig,update_img,300,interval=30)\n",
    "    writer = animation.writers['ffmpeg'](fps=30)\n",
    "\n",
    "    ani.save('demo.mp4',writer=writer,dpi=dpi)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ani_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
