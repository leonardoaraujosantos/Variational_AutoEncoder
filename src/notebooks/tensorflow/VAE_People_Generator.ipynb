{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder Generator Tensorflow\n",
    "This should open a pre-trained VAE and become a Data generator\n",
    "\n",
    "#### References:\n",
    "* http://kvfrans.com/variational-autoencoders-explained/\n",
    "* https://github.com/kvfrans/variational-autoencoder\n",
    "* https://github.com/int8/VAE_tensorflow\n",
    "* http://int8.io/variational-autoencoder-in-tensorflow/\n",
    "* http://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in.html\n",
    "* http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html\n",
    "* https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "* https://jaan.io/what-is-variational-autoencoder-vae-tutorial/\n",
    "* https://arxiv.org/pdf/1606.05908.pdf\n",
    "* https://arxiv.org/pdf/1312.6114.pdf\n",
    "* http://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/\n",
    "* https://www.tensorflow.org/get_started/embedding_viz\n",
    "* https://www.youtube.com/watch?v=eBbEDRsCmv4\n",
    "* https://www.youtube.com/watch?v=bbOFvxbMIV0\n",
    "* https://www.youtube.com/watch?v=P78QYjWh5sM\n",
    "* https://github.com/normanheckscher/mnist-tensorboard-embeddings\n",
    "* http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models import VAE_Segnet_Generator\n",
    "model = VAE_Segnet_Generator(latent_size = 40)\n",
    "model_in = model.input\n",
    "model_out = model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select only the convs\n",
    "list_params = [v for v in tf.global_variables() if \"z_matrix\" in v.name or \"conv\" in v.name or \"Batch\" in v.name]\n",
    "#list_params = [v for v in tf.global_variables() if \"z_matrix\" in v.name or \"conv\" in v.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LATENT/z_matrix/weights:0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem inside the model the Batchnorm variables are BatchNorm_[1...7] but on the file \n",
    "# they are BatchNorm_7...13\n",
    "# A possible solution is to give to the saver object a dictionary\n",
    "# https://www.tensorflow.org/api_docs/python/tf/train/Saver\n",
    "# https://stackoverflow.com/questions/39740871/how-to-save-a-dictionary-of-variables-in-tensorflow-using-the-saver-object\n",
    "# dictLoadVariabel['Feature_Extractor/BatchNorm'+str(i)+'/beta'] = [tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Feature_Extractor/BatchNorm'+str(i)+'/BatchNorm/beta:0')[0]]\n",
    "\n",
    "list_params[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf.global_variables()\n",
    "dict_match = {}\n",
    "#dict_match[list_params[0].name] = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='LATENT/z_matrix/weights')[0]\n",
    "# dict['stuff_on_checkpoint]=stuff_on_model\n",
    "\n",
    "#tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='LATENT/z_matrix')\n",
    "# If this tf.get_collection return more than one element you will have the \"slice not slice issue\"\n",
    "dict_match['LATENT/z_matrix/weights'] = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='LATENT/z_matrix/weights:0')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'DECODER/dconv1/weights:0' shape=(3, 3, 32, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv1/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv2/weights:0' shape=(3, 3, 32, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv2/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv3/weights:0' shape=(3, 3, 32, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv3/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv4/weights:0' shape=(3, 3, 64, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv4/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv5/weights:0' shape=(5, 5, 128, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv5/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv6/weights:0' shape=(5, 5, 64, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv6/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv7/weights:0' shape=(5, 5, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'DECODER/dconv7/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tf.collection will search (on your graph) for some scope so it could return more than one thing....\n",
    "# Example this will return buch of stuff\n",
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='DECODER/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define saver objects to load the VAE generator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Slices must all be slices: <tf.Variable 'LATENT/z_matrix/weights:0' shape=(40, 2592) dtype=float32_ref>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-5c1beb341624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the saver object to load only the conv variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#saver_load_autoencoder = tf.train.Saver(var_list=list_params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msaver_load_autoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_match\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/leoara01/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, var_list, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, saver_def, builder, defer_build, allow_empty, write_version, pad_step_number, save_relative_paths)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_step_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_step_number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefer_build\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_saver_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leoara01/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1168\u001b[0m           \u001b[0mkeep_checkpoint_every_n_hours\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keep_checkpoint_every_n_hours\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m           restore_sequentially=self._restore_sequentially)\n\u001b[0m\u001b[1;32m   1171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       \u001b[0;31m# Since self._name is used as a name_scope by builder(), we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leoara01/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, names_to_saveables, reshape, sharded, max_to_keep, keep_checkpoint_every_n_hours, name, restore_sequentially, filename)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0munique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \"\"\"\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0msaveables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ValidateAndSliceInputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_to_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_to_keep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0mmax_to_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leoara01/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36m_ValidateAndSliceInputs\u001b[0;34m(self, names_to_saveables)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Slices must all be Variables: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_slice_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Slices must all be slices: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mslice_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0mslice_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_slice_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Slices must all be slices: <tf.Variable 'LATENT/z_matrix/weights:0' shape=(40, 2592) dtype=float32_ref>"
     ]
    }
   ],
   "source": [
    "# Define the saver object to load only the conv variables\n",
    "#saver_load_autoencoder = tf.train.Saver(var_list=list_params)\n",
    "saver_load_autoencoder = tf.train.Saver(var_list=dict_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph and create session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/leoara01/work/Variational_AutoEncoder/src/notebooks/tensorflow/save/model-309\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Avoid allocating the whole memory\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "#sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Initialize all random variables (Weights/Bias)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Restore only the weights (From AutoEncoder)\n",
    "saver_load_autoencoder.restore(sess, \"/home/leoara01/work/Variational_AutoEncoder/src/notebooks/tensorflow/save/model-309\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some input from the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a latent as a normal distribution with size 20, mean 0, variance 1\n",
    "latent = np.random.normal(0, 1, [1,20])\n",
    "\n",
    "#latent = np.ones([1,20])\n",
    "#latent[0,1:10] = -1\n",
    "\n",
    "out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "plt.imshow(out_img.reshape([28,28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dpi = 50\n",
    "\n",
    "def ani_frame():\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    im = ax.imshow(np.random.rand(28,28),cmap='gray',interpolation='nearest')\n",
    "    #latent = np.random.normal(0, 1, [1,20])\n",
    "    #out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "    #im = ax.imshow(out_img.reshape([28,28]),cmap='gray',interpolation='nearest')\n",
    "    \n",
    "    im.set_clim([0,1])\n",
    "    fig.set_size_inches([5,5])\n",
    "\n",
    "\n",
    "    tight_layout()\n",
    "\n",
    "\n",
    "    def update_img(n):\n",
    "        #tmp = rand(300,300)\n",
    "        #im.set_data(tmp)\n",
    "        latent = np.random.normal(0, 1, [1,20])\n",
    "        out_img = sess.run(model_out, feed_dict={model_in:latent})\n",
    "        im.set_data(out_img.reshape([28,28]))\n",
    "        return im\n",
    "\n",
    "    #legend(loc=0)\n",
    "    ani = animation.FuncAnimation(fig,update_img,300,interval=30)\n",
    "    writer = animation.writers['ffmpeg'](fps=30)\n",
    "\n",
    "    ani.save('demo.mp4',writer=writer,dpi=dpi)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ani_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
