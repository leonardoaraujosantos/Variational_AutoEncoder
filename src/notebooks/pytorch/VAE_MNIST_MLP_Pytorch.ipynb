{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder (MLP) Pytorch\n",
    "Train a variational autoencoder with MNIST dataset\n",
    "\n",
    "#### References:\n",
    "* http://kvfrans.com/variational-autoencoders-explained/\n",
    "* https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "* https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "* http://wiseodd.github.io/techblog/2017/01/24/vae-pytorch/\n",
    "* https://github.com/ritheshkumar95/pytorch-vqvae\n",
    "* https://pytorch.org/docs/stable/distributions.html\n",
    "* https://ermongroup.github.io/cs228-notes/extras/vae/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.0\n",
      "Device: cpu\n",
      "Number of available GPUs: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.distributions.normal import Normal\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "batch_size = 128\n",
    "ZDIMS = 20\n",
    "epochs = 10\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "num_gpu = torch.cuda.device_count()\n",
    "print('Number of available GPUs:', num_gpu)\n",
    "\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download or load downloaded MNIST dataset\n",
    "# shuffle data at every epoch\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('data', \n",
    "    train=True, download=True,transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Same for test data\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, ZDIMS)\n",
    "        self.fc22 = nn.Linear(400, ZDIMS)\n",
    "        self.fc3 = nn.Linear(ZDIMS, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        # Sample from normal 0 mean unit variance distribution\n",
    "        eps = torch.randn_like(std)\n",
    "        # Reparametrization trick\n",
    "        guessed_z = mu + (eps*std)\n",
    "        return guessed_z\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        # Differentiable\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        # Non-differentiable\n",
    "        #z = torch.normal(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Train/Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 551.787048\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 297.048370\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 242.967133\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 221.661652\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 211.982361\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 217.327896\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 208.685181\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 205.022858\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 190.629333\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 189.730728\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 187.727722\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 179.755569\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 169.081406\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 160.769028\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 160.425735\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 159.927536\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 159.593201\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 159.492477\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 154.695786\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 152.364120\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 151.676254\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 149.511963\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 148.569458\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 141.505005\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 151.574875\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 154.419540\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 144.913223\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 147.151581\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 136.309326\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 133.201111\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 140.776184\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 139.020737\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 140.062592\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 137.883774\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 126.055984\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 137.088547\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 140.102219\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 128.674286\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 131.357361\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 138.028168\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 134.848480\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 134.525391\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 131.372070\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 129.471481\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 130.104431\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 127.716492\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 131.860107\n",
      "====> Epoch: 1 Average loss: 164.1066\n",
      "====> Test set loss: 128.4132\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 128.241074\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 128.830322\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 127.489296\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 127.648804\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 128.346817\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 124.640640\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 127.360382\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 129.539154\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 128.420502\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 125.461792\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 125.977287\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 119.712646\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 127.386940\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 120.370674\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 123.308525\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 120.885063\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 128.384796\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 125.670532\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 121.894180\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 126.203568\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 121.064064\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 117.907272\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 122.226868\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 122.997787\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 122.129837\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 123.269379\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 119.394722\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 121.714226\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 115.484436\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 120.472916\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 119.622780\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 117.144188\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 119.198311\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 119.411659\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 118.515106\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 116.038025\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 118.072906\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 119.608978\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 123.470238\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 112.180206\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 115.121750\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 120.725082\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 116.492455\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 116.426353\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 118.199387\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 122.327087\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 114.322556\n",
      "====> Epoch: 2 Average loss: 121.8952\n",
      "====> Test set loss: 116.3557\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 116.684875\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 117.485771\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 117.884865\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 117.716835\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 121.664108\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 117.543846\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 114.647545\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 111.122971\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 115.261833\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 117.525574\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 117.079498\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 114.881821\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 117.962601\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 113.422737\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 111.137856\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 112.105141\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 119.290863\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 114.453140\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 120.086960\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 118.249557\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 115.442238\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 117.101898\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 114.620392\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 115.265068\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 113.825829\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 115.892593\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 116.479248\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 115.258606\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 116.174347\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 109.215027\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 112.950195\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 114.574829\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 110.468941\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 112.639420\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 117.892960\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 111.068649\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 115.545326\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 108.018829\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 113.871704\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 111.972046\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 109.001633\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 112.625610\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 117.390739\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 115.526741\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 111.347046\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 114.914032\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 116.796555\n",
      "====> Epoch: 3 Average loss: 114.7186\n",
      "====> Test set loss: 112.1213\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 115.090317\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 109.488762\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 110.745857\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 114.911057\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 113.204704\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 116.925262\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 114.014442\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 113.265739\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 109.905830\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 110.786850\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 107.775467\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 111.703430\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 114.294067\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 115.763214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 112.442581\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 112.372673\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 114.094131\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 112.781418\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 107.066338\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 108.909882\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 113.457367\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 108.478455\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 114.028839\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 113.726341\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 113.876747\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 112.142204\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 112.191269\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 109.592323\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 113.280220\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 110.649132\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 107.570801\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 112.243889\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 109.462791\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 107.637344\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 108.257484\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 111.288803\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 107.404289\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 109.923141\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 110.306694\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 114.428619\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 111.113335\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 111.686127\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 109.783249\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 113.356529\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 106.822052\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 109.514824\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 109.580551\n",
      "====> Epoch: 4 Average loss: 111.7153\n",
      "====> Test set loss: 109.8186\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 113.483963\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 109.419334\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 111.736168\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 111.810974\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 110.339828\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 107.757217\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 110.777763\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 113.359970\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 109.835709\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 110.448730\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 109.233994\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 110.132126\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 108.171982\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 108.993759\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 113.675316\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 107.264748\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 114.147400\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 109.079651\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 107.845749\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 109.914742\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 108.595314\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 112.290474\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 110.575706\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 111.166077\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 105.315872\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 109.298721\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 105.126213\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 112.121948\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 106.820114\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 112.447739\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 107.014587\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 109.827591\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 106.791077\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 110.228027\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 114.817291\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 109.727745\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 108.590149\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 105.101669\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 108.460495\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 114.224625\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 108.049133\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 106.707016\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 108.277512\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 111.677757\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 107.118279\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 105.554413\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 109.233902\n",
      "====> Epoch: 5 Average loss: 109.9332\n",
      "====> Test set loss: 108.5975\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 110.936325\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 109.314056\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 109.787079\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 110.441422\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 108.100304\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 112.027237\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 115.600479\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 112.673470\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 113.034668\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 111.045502\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 109.132950\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 112.076637\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 110.297760\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 109.543724\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 108.333199\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 107.934700\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 111.195053\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 107.442818\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 107.422050\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 104.895180\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 108.297462\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 109.301895\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 110.423630\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 105.909386\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 108.182327\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 109.241425\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 106.205841\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 111.382851\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 112.791176\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 110.591713\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 106.851295\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 109.092697\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 106.864700\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 109.511887\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 107.207382\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 110.236092\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 109.082626\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 107.707367\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 104.190155\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 105.428551\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 110.814255\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 112.302612\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 107.418304\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 108.797485\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 108.908455\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 104.604286\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 106.908875\n",
      "====> Epoch: 6 Average loss: 108.7796\n",
      "====> Test set loss: 107.5416\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 108.021240\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 109.829453\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 110.344017\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 107.277145\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 109.041092\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 109.357132\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 108.234116\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 108.223846\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 103.708778\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 111.360687\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 105.173874\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 108.859947\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 111.554794\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 108.175919\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 113.162766\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 109.853889\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 112.157600\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 106.350830\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 108.096626\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 109.315147\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 109.729355\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 107.823341\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 107.357132\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 107.665680\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 105.907669\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 110.642303\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 113.668457\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 105.026672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 110.936012\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 104.405571\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 104.921310\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 109.804291\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 107.881287\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 105.407799\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 106.517616\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 107.404465\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 108.473541\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 106.090683\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 107.122879\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 110.688354\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 109.508087\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 106.980362\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 106.017075\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 104.094521\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 108.281967\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 106.971008\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 103.746872\n",
      "====> Epoch: 7 Average loss: 107.9373\n",
      "====> Test set loss: 106.8505\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 106.462585\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 113.545593\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 109.228333\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 108.016640\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 105.252350\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 104.072853\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 105.793671\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 105.041359\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 111.968697\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 105.006012\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 108.114655\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 105.379738\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 107.444824\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 108.205635\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 105.632584\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 109.528625\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 108.292648\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 106.068550\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 109.783234\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 110.652603\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 104.769608\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 108.334488\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 109.277069\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 113.151657\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 105.052521\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 106.038681\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 103.376534\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 110.006973\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 108.642487\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 104.090347\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 109.174164\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 105.346664\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 106.454163\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 108.410614\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 106.457825\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 104.596504\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 105.306656\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 104.491730\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 104.463959\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 104.894989\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 108.688560\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 104.961693\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 108.394012\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 106.378151\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 111.017288\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 105.062134\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 104.810158\n",
      "====> Epoch: 8 Average loss: 107.2838\n",
      "====> Test set loss: 106.4149\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 107.545746\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 104.454788\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 106.411491\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 104.189850\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 109.201668\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 106.124657\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 106.558434\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 104.337273\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 108.553192\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 107.425934\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 105.692184\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 111.545029\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 106.480179\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 106.464218\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 106.821060\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 112.309845\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 107.782639\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 106.982918\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 109.865776\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 109.937683\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 104.915489\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 106.903900\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 109.070435\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 106.687172\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 104.792191\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 106.041153\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 104.975075\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 106.296265\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 101.968056\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 107.336151\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 101.887146\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 105.006737\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 108.665207\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 105.246544\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 104.853218\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 105.293724\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 106.692719\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 103.931732\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 109.765923\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 111.670822\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 107.390274\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 104.215027\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 105.741913\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 104.756226\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 103.400604\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 101.577576\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 106.438316\n",
      "====> Epoch: 9 Average loss: 106.7301\n",
      "====> Test set loss: 105.8965\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 105.000366\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 110.751785\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 106.585526\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 107.730026\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 105.625153\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 110.393265\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 109.127541\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 105.413956\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 108.536125\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 104.574188\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 105.022186\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 104.825439\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 107.371902\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 103.046196\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 105.599556\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 102.758240\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 106.338516\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 104.598152\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 103.048172\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 108.745674\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 102.498001\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 108.774651\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 106.647850\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 108.414795\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 109.378319\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 106.142807\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 104.926262\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 102.772186\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 105.731033\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 111.022049\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 106.062424\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 107.542267\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 107.158745\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 111.689163\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 105.566307\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 101.160934\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 106.960136\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 107.764450\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 104.059601\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 110.463867\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 103.499077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 109.143372\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 105.320190\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 110.209747\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 105.543938\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 104.061401\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 109.074913\n",
      "====> Epoch: 10 Average loss: 106.2971\n",
      "====> Test set loss: 105.8168\n"
     ]
    }
   ],
   "source": [
    "# 206 loss\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(64, 20).to(device)\n",
    "            sample = model.decode(sample).cpu()\n",
    "            save_image(sample.view(64, 1, 28, 28),\n",
    "                       'results/sample_' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
